\chapter{Considerations for the design of the system}
\label{chap:basics}

%\content{Oli}
When designing a honeypot system various approaches can be used to achieve a similar goal. 
Different approaches have a range of advantages and disadvantages.
In the following chapter, multiple concepts for different design questions will be shown and discussed.
A target architecture will be determined.

\section{Justification for this "budget" honeypot approach}\label{sec:budget}
%\content{Jani}
As we already discussed in the introduction, deploying a honeypot on a server used in production comes with some challenges and limitations. On the one hand, we do not want to interfere with commands from a legitimate administrator and make things unnecessarily difficult to use. On the other hand, an attacker on the machine should not have access to real data and therefore, the real file system has to be hidden in a way that it is not too obvious.

A possible use case for this budget-approach might be in embedded systems. For example an electricity supplier might operate an electrical grid spread over a large area. This grid is constantly monitored at hundreds and thousands of locations to make sure that everything works as expected and within given limits. These sensors produce measurement data and send these data to a some central hub, which means they are somehow connected to the internet, most likely over some virtual private network.
On the other hand, these sensor platforms are not under manual administration very often. They are deployed in bulk and should operate for many years without needing maintenance. Therefore these embedded systems might be a potential use case for the budget honeypot approach. Legitimate administrators do not constantly use them and might lock themselves out and also these systems are connected to some central instance, enabling automatic sharing of intelligence about an attacker.

Of course this comes with some limitations. Most embedded systems do not contain a lot of computing power, as they are designed to only gather and transmit some sensor data. This would have an impact on the technologies that can be used in the honeypot system. For example a virtual environment might not be possible. Also in the vent of an attacker escaping the honeypot simulated system, the company would have to disconnect the compromised device entirely from their systems and potentially drive several hours to the location to replace the infected system.

To put it all in a nutshell, this approach might not have an ideal use case at the moment. But this project is not about inventing the latest state-of-the-art honeypot technology but rather about learning techniques to intercept commands and fake a file structure on a Linux-based machine.

\section{How is the "fake" system simulated?}
%\content{Oli}
When creating a honeypot system that is supposed to create the impression or illusion of a real system, it is essential to simulate the effects of various commands on the real operating system.
This means if an attacker executes the command \texttt{rm folder1} he expects this directory to not show up the next time he uses the \texttt{ls} command.
Since all commands are intercepted by the honeypotting system, the effects of commands used by the attacker must be processed and kept track of.
To achieve this goal, various approaches are conceivable.

\subsection{Using a different file system root}
The first idea was to utilize already existing features of Linux.
One of these features is the \texttt{chroot} command.
It allows the user to define a custom system root for the current process.
Changing the root not only switches the file system to a new directory but also runs following commands with binaries present in the new system root.
Since the system root is changed, all directories containing binaries like \texttt{/usr/bin/bash} are changed as well.
This would open the possibility to directly redirect commands run by an adversary to a separated system, while preserving all functionality of these commands.
The \texttt{rm} command for example would delete a file in the replicated filesystem without altering the real data.
This kind of approach was also used in the past to realize a similar honeypotting approach.
Bill Cheswick used the \texttt{chroot} method as early as 1991 to track the behavior of an adversary \cite{cheswick1992evening}.

Even tho this method provides a lot of nice properties for the realization of the project it also comes with a few serious disadvantages.
Firstly, in contrast to many statements found online, \texttt{chroot} is not a jail or sandbox in the regular sense.
Even though there are possibilities for a defender to hide the fact that an attacker is currently inside a \texttt{chroot} environment, an experienced adversary can still figure out the situation.
Furthermore once an attacker is aware of the \texttt{chroot} environment, it is easy for him to escape.
Another negative point is the fact, that simulating directory or filesystem related commands is very simple to achieve via this method, other commands that are network or process related cannot be implemented easily.

\subsection{Docker}
The second approach utilizes a similar method like \texttt{chroot}.
This time docker containers are used to redirect an adversary to a virtualized system.
Compared to the previous idea, this provides a better level of abstraction and separation to the actual production system.
Escaping a well set up docker container is hard to impossible and even network and process related commands can be run inside the container.
This is due to the fact that a docker container simulates an operating system as a whole, compared to only the directory structure from \texttt{chroot}.
Unfortunately a docker container is also easy to spot for a well trained attacker.
Furthermore this approach not only requires additional software, it also needs further computing resources like CPU and RAM.
In accordance to the \textbf{budget idea} (see \autoref{sec:budget}) this contradicts the original purpose of using limited resources to realize a honeypot.

\subsection{Journal / Internal}
The final approach does not use some kind of "virtualization" technology, but rather tracks and simulates all system behaviors at runtime.
A base structure is defined and loaded at the start of the honeypot program.
All changes and commands as well as applications are tracked and the results mapped onto the base data.
Every action is written into a data structure.
This could be in the form of a journal.
A journal consists of ordered list of commands an adversary used on the system.
If a "fake" output should be provided to the attacker, the program "re-runs" all commands currently in the journal.
This approach does not consume a lot of resources, which is a big advantage given our scenario. It also is not persistent and can be reset quickly, as the simulated environment is generated and then kept in memory during program execution. Simply restarting the process resets the environment. Therefore this approach seems to be the most promising and will be used.


\section{Activation / Deactivation of the System}
\subsection{When does it activate?}
%\content{Oli}
Another question to ask is, whether the honeypot system is activated by a particular trigger and if so, what kind of trigger could be used?
In contrast the second approach would be to make the honeypot active by default.
This has the advantage, that no attacker will be missed.
However, this constant activation may inconvenience legitimate users interacting with a system, as they would have to use some kind of deactivation, which is discussed in the next section.

As for the method to activate the honeypot through a specific trigger.
This could be an access to a specific file or location, such as monitoring access to \texttt{"/etc/passwd/"}.
This type of trigger could be chosen depending on the most commonly accessed locations during an attack.

For this first proof-of-concept version of the honeypot system, we might also think of activating the honeypot system on a user bases. For example, we might secure all legitimate accounts on the system with strong passwords and state-of-the-art Two Factor Authentication except for one specific user account that we want an attacker to find and use. Therefore, our system could be limited to only intercept commands from this one specific user account, although other triggers based on some rules might be used later.

\subsection{How does it deactivate?}
%\content{Anna}

When activating the honeypot system, it's important to ensure that legitimate users can still access the genuine functionalities of the command line. One method is to globally deactivate the honeypot with password protection, enhancing security even if attackers discover how to deactivate it. A similar approach would be allowing only certain commands and disallowing them after they are not needed anymore. Both these approaches expose the system to attacks temporarily.  

Another strategy involves using different commands that are created to replace the forged command. These commands provide the legitimate functionality of the forged command but have a different name. However, this requires developing and learning a new command scheme, which entails a certain level of inconvenience and could be confusing for new and inexperienced users.    
To mitigate this, a prefix or suffix could be added to the original command (e.g allow ls or ls2). Although using different command names provides a clear distinction between forged and real commands, it can be easily detected and bypassed by an attacker, if the attacker is aware of the new names.

Additionally, it's essential to address scripts that rely on system commands. If the original commands are replaced and don't function anymore, scripts using these commands will also fail. One solution is to modify the commands within the scripts to match the new ones. Alternatively, if the approach is chosen to temporally deactivate the honeypot, the scripts will resume functioning, which could be a feasible solution depending on the use case. Another option would be adding a user who is excluded from the honeypot's effects, allowing them to execute the original commands needed to run the scripts.

As discussed in the previous section, these problems can be avoided when using the honeypot technology on a user basis. Legitimate users do not interfere with the honeypot system whereas an attacker that uses the least secured, specifically and obviously placed account is trapped.

\section{Different Command Modification and Tracing Approaches} 
%\content{Malte}
The following section describes techniques that can be considered to modify linux system cli commands so that they do not serve their original purpose but emulate the original system behavior. This way a potential intruder will not be misguided, while his actions can be monitored without him actually doing harm or changing the system. 

\subsection{execve()}
%\content{Jani}
The "execve" or "execute program" syscall within UNIX operating systems executes a new program within a current process. There is a whole set of commands starting with exec*. They provide almost the same functionality but differ in the way they expect and handle arguments \cite{execve}:

\begin{table}[H]
    \centering
    \begin{tabular}{c | l}
        Command & Description \\
        \midrule
        exec* & \parbox{12cm}{Replaces the current process image with a new process image.}\\
        \midrule
        execl* & \parbox{12cm}{Expects a list of arguments in the form of pointers to null-terminated strings.}\\
        \midrule
        execv* & \parbox{12cm}{Expects a vector of arguments in the form of pointers to null-terminated strings.}\\
        \midrule
        exec*p & \parbox{12cm}{Just like the shell, the program will look for the executable file in the list of directories specified in the PATH environment variable.}\\
        \midrule
        exec*e & \parbox{12cm}{Allows to specify the environment for the new process. This is done using the envp-argument which is an array of pointers to null-terminated strings.}\\
    \end{tabular}
    \caption{Difference of exec*-commands}
    \label{tab:my_label}
\end{table}

Once a user executes a command within the UNIX command line e.g. "bash", the process of the bash is then forked via the "fork" system call as a child process of the main "bash" process \cite{fork}. Afterwards, the "execve" system call then replaces the process image of said child process with that of the actual command program which is then executed to return the program output to the user \cite{execve}. It is important to note that not all UNIX commands can be traced with "execve" for example if they directly interact with the kernel or are builtin shell commands. Commands such as "kill" directly interfere with processes by sending signals to said processes without using the "execve" system call \cite{kill}.

%\todo[inline]{Baustelle}
%\ wer schreibt das hier weiter?
%Next up:
%- fork or clone create a new "child process" from a parent process
%- execve replaces the current context of the process with a new one (without creating a new process)
%- exec*e - allows to specify an environment for the new process - that is what we want, can redirect calls
%- execv* - vector of arguments, list might also be possible

%- “Out-of-the-Box” Monitoring of VM-Based High-Interaction Honeypots
%\cite{Xuxian2007}



\subsection{eBPF}
Extended Berkeley Packet Filter (eBPF) is a technology which enables programming of extensions for the linux kernel functionality without changing the source code of the kernel or loading kernel modules. eBPF can be utilized to run sandboxed programs within the operating system to add additional capabilities to the operating system at runtime. In the particular case of the honeypot eBPF can be used to run custom code once specific pre-defined kernel hooks such as system calls, function entries/exits, kernel tracepoints etc. are passed. In case that there are no pre-defined hooks present, it is also possible to create so called kernel probes (kprobe) or user probes (uprobe) to attach the program nearly anywhere in the kernel. This way the eBPF capabilities can be utilized for probing specific system calls such as "execve" to trace UNIX commands and extract details such as process IDs and command parameters \cite{bcc}.\\\\ The implementation is done via the python framework bcc which enables the coding of eBPF C-programs embedded into python source. The following illustration depicts this architecture in detail and shows the eBPF interacting with the System Call Interface (SCI). 
%\content{Malte -> Ausformulierung einzelner eBPF Komponenten}
\bild{bilder/ebpf.png}{eBPFs with python bcc}{eBPF with python bcc \cite{bcc}}
% @Malte # macht das Makro kaputt haha

\subsection{ptrace()}
"ptrace" is a system call that enables us to control the execution of another process by attaching and adding breakpoints for debugging purposes \cite{ptrace}. Therefore, "ptrace" can be utilized to debug processes and halt the execution flow. In combination with eBPF this would allow for modification and interception of processes that were traced. 

\subsection{Changing the original binary or using different binaries}
As already discussed we do not want to change binaries or introduce additional binaries to the system that are named slightly different. This does hinder normal system users from administrating the machine and might interfere with execution of scripts. As the goal is to implement this honeypot approach on an already in-use system, an administrator would have to be aware of the honeypot running during all of his actions on the system, which is hard when administrating many servers in a network during the day. Also some scripts or third party programs for network monitoring or malware detection might not work as expected when we mess with the standard system binaries. Therefore this option is not further considered.
%\subsection{Using a different binary}

\section{Which commands are changed / intercepted?}
%\content{Anna}
Another critical aspect of designing this honeypot system is selecting the commands to be modified. The objective is to alter the behavior of commands that are commonly utilized by potential attackers. This can be approached in various ways. 
One approach would be examining the most popular general commands used in the Linux command line interface by regular users. Another approach is considering the most popular commands used in an attack scenario. 

Numerous websites offer lists of commonly used Linux commands to assist beginner users in familiarizing themselves with the operating system. These serve as a starting point for our selection process. For instance, a popular educational platform like Geeks for Geeks recommends these 25 fundamental Linux commands:\newline 
\texttt{ls, pwd, mkdir, cd, rmdir, cp, mv, rm, uname, locate, touch, ln, cat, clear, ps, grep, echo, wget, whoami, \\sort, cal, wheris, df, wc} \cite{noauthor_25_2023}.

In a 2007 experiment conducted by Ramsbrock et al., researchers examined the specific actions taken by an attacker and the order in which they occured. To gain more information about the systems software attackers used the commands: \newline 
\texttt{w, id, whoami, last, ps, cat /etc/*, history, cat .bash\_history, php -v}. \newline
To install a programm attackers used the following commands: \newline 
\texttt{tar, unzip, mv, rm, cp, chmod, mkdir}. \newline
When downloading a file \texttt{wget, ftp, curl, lwp-download} were used the most. In order to run files the \texttt{./} was used. Some attackers modified the path variable to run programs without the \texttt{./} notation. Some also used perl scripts, so they also included \texttt{perl} and \texttt{*.pl}. When changing the password of a compromised account the command \texttt{passwd} was used. Commands for checking the hardware configuration include \texttt{uptime, ifconfig, uname, cat /proc/cpuinfo}. Lastly, \texttt{export, PATH=, kill, nano, pico, vi, vim, sshd, useradd, userdel} were used to change the system configuration. Certain routine commands made up 34.08 percent of all used commands. These commands include: \texttt{cd, ls, bash, exit, logout, cat} \cite{4272962}.

Knöchel and Wefel 2022 compiled the following list of most utilized commands from their findings observing the behaviour of attackers on a high-interaction Linux honeypot: \newline
\texttt{ls, df, ifconfig, w, who, netstat, ps, top, uname, lscpu, curl, wget, ftp, git clone, scp, perl, python, bash, sh, chpasswd, passwd, useradd, rm, cat \\/dev/null >, crontab -r, history -c, kill, pkill, killall} \cite{9943718}.

In 2013, Kheirkhah et al. conducted an experimental study showing a list of the most used commands entered by attackers during their honeypot experiments: \newline 
\texttt{w, uname, wget, id, ls, cat/proc/cpuinfo, uptime, ps, ls-a, passwd, whoami, halt, help, history, netstat, php-v, ifconfig} \cite{Kheirkhah13}.

The final list consists of a combination of general commands and commands used in attacks that might be useful to intercept and forge in a honeypot system. Commands that have no impact on the system, such as "clear" have been excluded. The final prototype will have a exemplary implementation of a small number of these commands.

To better understand the influences the commands have on each other, they can be categorized into different types. 
When analyzing the order of commands used in attacks, various approaches can be chosen. 
For instance, the Cyber Kill Chain provides a structured framework for dividing attacks into distinct phases. It is a attack modeling technique, which defines an attack as a chain of actions. It has seven steps described by Al-Mohannadi et al. \cite{7592703}:
\begin{enumerate}
    \item Reconnaissance: Gathering information before the attack.
    \item Weaponization: Creating a malicious payload to send to the victim. 
    \item Delivery: Sending the malicious payload to the victim.
    \item Exploitation: Victim needs to download the payload. 
    \item Installation: Executing malware on the infected system. 
    \item Command and control: creating a command and control channel to access the internal assets of the victim
    \item  Action on objective: Attacker achieves his goal on the victims system
\end{enumerate}
When analyzing the cyber kill chain, the actual execution of commands only starts in stage six "command and control" and continues in the seventh stage "Action on objective". This makes it harder to map our commands into different stages of the attack.
Alternatively, another approach proposed by Ramsbrock et al. could be used. The found commands are divided into seven states that represent the typical observed actions \cite{4272962}:
\begin{enumerate}
    \item Check Software Configuration:  The attacker gains more information about the systems software and it's users.
    \item Install a program: The attacker installs software on the system
    \item Download: The attacker downloads files remotely.
    \item Run a program: The attacker runs a program that was not originally part of the system 
    \item Change the account password: Changing the password for the compromised account  
    \item Check the hardware configuration: The attacker gains more information about the systems hardware(uptime, network, CPU speed)
    \item Change the system configuration: The attacker changes the state of the system permanently.
\end{enumerate}
This approach is simplified and used in our command overview. States 1 and 6 are combined into one state: "Finding out information about the system". State 3,4, and 5 are combined into: "Download, install, and run programs". The last state is called "changing the state of the system" and consists of states 7 and 5. 



\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering\arraybackslash}p{3cm}|c|c|}\hline
        Basic commands & cd & Change directory\\
         & ls & List directory contents\\
         & rmdir & Remove empty directory\\
         & mkdir & Create directory\\ \hline
         
         1. Finding out information about the system & cat & Concatenate and print files\\
         & df & Check details of file system \\
         & history & Show command history\\
         & php-v & Show php version\\
         & uname & Get basic information about the OS\\
         & locate & Find a file in the database\\
         & ps & Display processes\\
         & grep & Search for a specific string in an output\\
         & whoami & Displays current username\\
         & df & Check details of a file system\\
         & w & Information about current users\\
         & id & Find out user and group names and ids\\
         & last & Display the history of last logged in users\\
         & uptime & Find out how long the system is active\\
         & ifconfig & Display current network configuration information\\
         & crontab & Submit, edit, list, or remove cron jobs\\
         & nmap & Network scanning\\
         & ping & Send packets of data\\
         & arp & Display and modify arp entries\\
         & traceroute & Trace IP packet path\\
         \hline

         2. Download, install and Run programs & cp & Copy files\\
         & mv & Rename and replace file\\
         & rm & Delete files\\
         & wget & Download files\\
         & touch & Create empty file\\
         & ln & Create shortcuts\\
         & ftp & Ftp connection\\
         & curl & Download and upload data to a server\\
         & unzip & Unzip file\\
         & chmod & Set or modify a file's permissions\\
         & Nano, pico, vi, vim & File Editor\\ \hline
         
         3. Changing the of the system & kill, pkill, killall & Terminate process\\
         & useradd & Add user account\\
         & userdel & Delete user account\\
         & halt & Stop all CPU functions\\
         & passwd & Set and change passwords for users\\ \hline

    \end{tabular}
    \caption{Final List of commands}
    \label{tab:my_label}
\end{table}


\subsection{Relationship between commands}
%\bild{bilder/commands.png}{Relationship between Linux commands}{Relationship between Linux commands}

\bild{bilder/commandsnewdrawio.png}{Relationship between Linux commands}{Relationship between Linux commands}

The graph illustrates the relationships between selected commands and their influences. For instance, the \texttt{cd} command is influenced by \texttt{rmdir}. Since \texttt{rmdir} deletes directories, it restricts \texttt{cd} from navigating into those directories. Additionally, there are commands, such as \texttt{history}, influenced by all commands, and commands like \texttt{ifconfig} which are not influenced by any other command. It is important to note that this overview only contains the base commands without considering different flags or endings like \texttt{-a} for simplification purposes. 

%\ Vorschlag von Jani, bitte fachlich auf Korrektheit prüfen
The figure suggests splitting commands into three groups: 
\begin{enumerate}
    \item Commands to find out information about the system
    \item Commands to download, install and run programs
    \item Commands to change the state of the system
\end{enumerate}

Furthermore commands in these groups can be split into classes:
\begin{itemize}
    \item File system commands
    \item Network commands
    \item Commands that influence user accounts
    \item Commands that influence processes and the overall system state
\end{itemize}

When intercepting these four classes of commands, we notice that we have to define an environment and accordingly a data structure to simulate parameters that can be used by the classes of commands. For example, we have to define a virtual file system stored in a data structure that can be viewed and manipulated using file system commands such as \texttt{cd}, \texttt{mkdir} and \texttt{touch}. We also need an independent data structure providing a virtual network that can be read and used using network commands such as \texttt{ping}, \texttt{arp} and \texttt{nmap}.

These are the two main environments we have to simulate. On top, interactions like altering and creating user accounts and processes pose another challenge. Commands that interact with user accounts require dedicated structures to simulate user-related operations, such as creating, modifying, or managing accounts dynamically. Similarly, commands influencing processes or retrieving system state, such as information about active users or sessions, necessitate an additional abstraction layer. This layer complements the virtual file system and network structures to fully simulate the environment.

\section{Ways to hide honeypot processes and files}
In order to deceive the attacker inside the honeypot certain processes and files must be hidden. 
Linux provides several methods for hiding processes and files, some of which are outlined below. 

Regular Linux user accounts typically have the ability to view a Process ID (PID) listing using commands such as \texttt{ps}, \texttt{pgrep}, and \texttt{pidof}. However, to hide processes from specific users, the \texttt{hidepid} feature can be used. By mounting the \texttt{/proc} file system with the \texttt{hidepid=2} option, process files become invisible to non-root users. It's worth noting that although the existence of a process can still be learned through other means, this approach limits visibility to unauthorized users \cite{emad-al-mousa_how_2022}.
Additionally, there are also tools available for hiding processes, commonly used to hide malicious programs. For instance, \texttt{Xhide} can be used to mask processes by giving them the appearance of running as another process. Another tool called \texttt{Libprocesshider} can hide processes from commands like \texttt{ps}, \texttt{top}, and \texttt{lsof} by editing the source code and including the program that needs to be hidden \cite{noauthor_difference_2020}.
Modifying the source code of commands like \texttt{ps} could also be a way to conceal processes \cite{noauthor_difference_2020, borello_hiding_2014}.
Another potential approach is to alter the \texttt{readdir()} function within the \texttt{libc} library and incorporate code to filter out access to certain \texttt{/proc} files \cite{borello_hiding_2014}. The last approach could be intercepting and modifying the system calls directly in the kernel with a custom module \cite{borello_hiding_2014}.

Similarly, there are also multiple options to hide files in the Linux file system. Naturally, it is possible to create hidden files by adding a period (.) to the beginning of the file name or utilizing the "hidden" attribute. However these files still remain visible to everyone, as a simple \texttt{ls -a} will reveal them. Another straightforward method involves altering directory permissions to restrict the access to files. There are also stenographic approaches that hide files by compressing them and concatenating them with other files \cite{sk_steganography_2019}.

In our honeypot approach, the system mimics the output of commands such as \texttt{ps} and replicates the entire file system. This ensures that attackers are unable to detect any files or processes they are not supposed to see. 

\section{Logging}
%\content{Anna}
In order to later learn from the attackers command patterns in a attack scenario each executed command should be logged. This could be done in different ways. 

One possible way is using a journal. \texttt{Journalctl} is a tool used to query and display logs from \texttt{journald}, the logging service of \texttt{systemd} \cite{noauthor_journalctl_2023}.
One of the primary benefits of using journald is its ability to provide a detailed and clear timeline of events. This feature is valuable for forensic analysis, allowing administrators to trace the actions of an attacker step by step. Journald stores logs in a binary format, which is proprietary. This can pose challenges in terms of compatibility and flexibility, as specialized tools (like journalctl) are required to read these logs. There are also questions regarding the scalability. As the volume of log data increases, performance issues may arise. Especially in our approach, performance and resources of the host are limited.

Another common method is simple logging in plain text files. This method is straightforward but comes with its own set of pros and cons. It is easy to implement and does not require additional software or complex configurations. Similar to journald, using custom formats or structures in file-based logging can lead to compatibility issues. As with journald, plain text file logging may face scalability issues as the volume of logs grows. Additionally, since the logs are stored on the same system, they can be found and destroyed by an attacker. This makes it a less secure option compared to methods that store logs off-system.

Network Service or Security Information and Event Management (SIEM) solutions offer a more advanced and secure approach to logging. By storing logs off-system, these solutions make the logs immutable. An attacker cannot easily tamper with or destroy the logs. SIEM solutions also often come with powerful analytics and correlation capabilities, enabling proactive threat detection and response. Con of that approach are that implementing a network service or SIEM solution requires additional systems and resources. This includes dedicated servers, network bandwidth, and potentially significant financial investment. These solutions can also be complex to configure and maintain, requiring specialized knowledge and skills.

In our honeypot system, simple logging in plain text files seems to be appropriate. As we hide the real system from an attacker, he does not have direct access to this log in order to destroy it. Also the small impact on performance is a strong argument in favor of this approach.